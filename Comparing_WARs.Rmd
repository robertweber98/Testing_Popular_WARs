---
title: "Comparing WARs"
author: "Rob Weber"
date: "July 27, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r ridge regression}
# going to use the glmnet method of performing a ridge regression
library(glmnet)
# this gets a matrix of the model because the first argument of glmnet requires a matrix
mat <- model.matrix(W ~ fangraphs_WAR + br_WAR + bp_WAR, df)
# this for the next argument
wins <- df$W
# this is the base ridge regression
ridge.reg <- glmnet(mat, wins, alpha=0, nlambda=100, lambda.min.ratio=0.0001)
# to get the best betas for predicting, we need to find the best lambda for doing so
set.seed(2017)
cv <- cv.glmnet(mat, wins, alpha=0, nlambda=100, lambda.min.ratio=0.0001)
best.lambda <- cv$lambda.min
# this shows the betas for the ridge regression using the best lamda 
predict(ridge.reg, s = best.lambda, type="coefficients")
```

They don't seem to be significantly different from one another, but, to find that out for sure, we can bootstrap the regression to find 95% confidence intervals.
- This next chunk is just in here as reference code. It took a few hours on my PC, so, I just wrote the data to a csv and uploaded it.
```{r bootstrapping}
set.seed(1)
100000 -> loops # number of times looped
# df to store the results
data.frame("Loop" = c(1:loops), "fangraphs_WAR" = 0, "br_WAR" = 0, "bp_WAR" = 0) -> df.test 
# this is essentially the same code as above
for(i in 1:loops) {
  sort(sample(1:30, 20, replace = FALSE)) -> selection
  df[c(selection), ] -> boot.df
  x <- model.matrix(W ~ fangraphs_WAR + br_WAR + bp_WAR, data = boot.df)
  y <- boot.df$W
  ridge.mod <- glmnet(x, y, alpha=0, nlambda=100, lambda.min.ratio=0.0001)
  cv.test <- cv.glmnet(x, y, alpha=0, nlambda=100, lambda.min.ratio=0.0001, grouped = F)
  best.lambda <- cv.test$lambda.min
  abs(as.vector(predict(ridge.mod, s = best.lambda, type = "coefficients"))[3:5]) -> df.test[i, 2:4]
}
```

```{r Significance}
# this creates a df to store the CIs
comp.df <- data.frame("WAR" = c("fWAR", "br_WAR", "bs_WAR"), "Lower" = 0, "Upper" = 0)
# the next three lines find the the 95% CI and store it in comp.df
as.vector(quantile(df.test$fangraphs_WAR, c(0.025, 0.975))) -> comp.df[1, c(2, 3)]
as.vector(quantile(df.test$br_WAR, c(0.025, 0.975))) -> comp.df[2, c(2, 3)]
as.vector(quantile(df.test$bp_WAR, c(0.025, 0.975))) -> comp.df[3, c(2, 3)]
# The next step I like to take is to look at a plot of the three distributions of betas
# need df.test long instead of wide for ggplot
gather(df.test[3:5], key = "WAR", value = "beta") -> df.test_long
ggplot(df.test_long, aes(x = beta, fill = WAR)) +
  geom_density(alpha = 0.3)
```
You can see pretty obviously in the plot, the distributions of the betas are all pretty close together and there is no chance that any of them have an overlap of 5% or less. Therefore, we can say with 95% confidence that none of these three of the most popular WARs are significantly better or worse than the others.
